{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6edce657-e03d-4b2a-86a2-8bfb1a8b9cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.28/06\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import ipympl\n",
    "import ROOT as r\n",
    "%jsroot on\n",
    "r.PyConfig.DisableRootLogon = True\n",
    "r.PyConfig.IgnoreCommandLineOptions = False\n",
    "import numpy as np\n",
    "from array import array\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from array import array\n",
    "import scipy.optimize as opt\n",
    "from glob import glob\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "db1b1732-aa28-454e-9145-f6fdc4121aea",
   "metadata": {},
   "source": [
    "path_to_rootf = \"~/xlc_sim_outputs/SimData_Histograms.root\"\n",
    "File1 = r.TFile.Open(path_to_rootf ,\"read\")\n",
    "\n",
    "tree=0\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1a04312d-87c8-45f3-88d5-a5e219c822c4",
   "metadata": {},
   "source": [
    "path_to_test_data = \"~/xlc_sim_outputs/flight_like/PD45_rotating.root\"\n",
    "test_data = r.RDataFrame('tree2',path_to_test_data)\n",
    "test_data = test_data.Filter(\"horizontal_pixel<=32\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "98ab27b0-148b-46e9-a80c-4616f596bbec",
   "metadata": {},
   "source": [
    "#path_to_test_data = \"~/xlc_sim_outputs/flight_like/xlcsimNon_Rotating.root\"\n",
    "#test_data = r.RDataFrame('tree2',path_to_test_data)\n",
    "xbin = np.arange(0.5,33.5,1)\n",
    "\n",
    "test_hist = test_data.Histo1D(('test_hist','test_hist',len(xbin)-1,xbin),'horizontal_pixel')\n",
    "c = r.TCanvas(\"\",\"\",500,500)\n",
    "test_hist.Draw('h')\n",
    "test_hist.Scale(1/test_hist.Integral(),\"width\")\n",
    "test_hist.GetXaxis().SetRangeUser(0,32)\n",
    "test_hist.GetXaxis().SetTitle(\"Horizontal Pixel Column\")\n",
    "test_hist.GetYaxis().SetTitle(\"Counts\")\n",
    "c.Draw('Hist')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7fcb72c9-f427-4dee-99f3-d3e9ea14f24e",
   "metadata": {},
   "source": [
    "fFile = r.TFile.Open(path_to_test_data)\n",
    "#fTree = fFile.Get(\"tree2\")\n",
    "fTree = fFile.Get(\"tree2\")\n",
    "test_hist = r.TH1D('test_hist','test_hist',len(xbin)-1,xbin)\n",
    "for event in fTree:\n",
    "    if fTree.horizontal_pixel < 32:\n",
    "        test_hist.Fill(fTree.horizontal_pixel)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7af1ae09-90d0-42b7-9010-25f2024d3394",
   "metadata": {},
   "source": [
    "Probabilities = np.zeros(len(sample_File.GetListOfKeys()))\n",
    "thetas = np.zeros(len(sample_File.GetListOfKeys()))\n",
    "\n",
    "for tree in range(len(sample_File.GetListOfKeys())):\n",
    "    sample_Tree = sample_File.Get(f\"tree_{tree}\")\n",
    "    sample_hist = r.TH1D('hist','hist',len(xbin)-1,xbin)\n",
    "    for event in sample_Tree:\n",
    "        if sample_Tree.horizontal_pixel < 32:\n",
    "            sample_hist.Fill(sample_Tree.horizontal_pixel)\n",
    "    chi2 = sample_hist.Chi2Test(test_hist,\"UU\")\n",
    "    Probabilities[tree] = chi2\n",
    "    thetas[tree] = tree\n",
    "    sample_hist.Delete()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0b7e0199-1fb5-4dec-9155-88bf7d516aeb",
   "metadata": {},
   "source": [
    "path_to_Unpolarized_Data = \"~/xlc_sim_outputs/flight_like/UnPolarized.root\"\n",
    "\n",
    "unpol_File = r.TFile.Open(path_to_Unpolarized_Data,\"read\")\n",
    "PD0_Tree = unpol_File.Get(f\"PD0\")\n",
    "unpol_hist = r.TH1D('unpol_hist','unpol_hist',len(xbin)-1,xbin)\n",
    "for event in PD0_Tree:\n",
    "    if PD0_Tree.horizontal_pixel < 32:\n",
    "        unpol_hist.Fill(PD0_Tree.horizontal_pixel)\n",
    "c = r.TCanvas(\"\",\"\",500,500)\n",
    "unpol_hist.Draw()\n",
    "c.Draw('Hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62e53f8-cda2-4854-9e6b-a2f6525ed290",
   "metadata": {},
   "source": [
    "## Next Step:\n",
    "\n",
    "Now that we have a good estimate for the PA and PD, we can repeat the process using the estimated PD to get a better estimate for PA, since we have these estimates we can also search a smaller space."
   ]
  },
  {
   "cell_type": "raw",
   "id": "c2528625-1b2f-4014-a426-c83604823188",
   "metadata": {},
   "source": [
    "probs = np.zeros(40)\n",
    "unpol_prob_dataframe = pd.DataFrame(index = np.arange(1,41,1))\n",
    "unpol_File = r.TFile.Open(path_to_Unpolarized_Data,\"read\")\n",
    "PD0_Tree = unpol_File.Get(f\"tree\")\n",
    "unpol_hist = r.TH1D('unpol_hist','unpol_hist',len(xbin)-1,xbin)\n",
    "\n",
    "for event in PD0_Tree:\n",
    "    if PD0_Tree.horizontal_pixel < 32:\n",
    "        unpol_hist.Fill(PD0_Tree.horizontal_pixel)\n",
    "        \n",
    "unpol_hist.Scale(1/unpol_hist.Integral(),\"width\")\n",
    "for i in range(40):\n",
    "    j = i+1\n",
    "    probs[i] = unpol_hist.GetBinContent(j)\n",
    "unpol_hist.Delete()\n",
    "unpol_prob_dataframe['Probs'] = probs\n",
    "unpol_prob_dataframe = unpol_prob_dataframe.loc[unpol_prob_dataframe.index < 32]\n",
    "unpol_prob_dataframe['pixel'] = np.arange(1,32,1)\n",
    "\n",
    "#display(unpol_prob_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb88affb-b756-452b-abb3-755dce2070d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polfrac_model(E,PD30,beta):\n",
    "    return beta*(E-30) + PD30\n",
    "\n",
    "def polang_model(E,PA30,gamma):\n",
    "    return gamma*(E-30) + PA30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efec034-cfa4-46a5-a263-07f10df1a142",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_test_data = \"~/xlc_sim_outputs/Test_EnergyDep10.root\"\n",
    "#path_to_test_data = \"~/xlc_sim_outputs/flight_like/PD45_rotating.root\"\n",
    "data_set = r.RDataFrame('tree2',path_to_test_data).AsNumpy()\n",
    "xbin = np.arange(0.5,33.5,1)\n",
    "PA_guess,PD_guess = 40,0.4\n",
    "opt_path = np.array([PA_guess,PD_guess])\n",
    "psf_e_steps = [20,30,40,50,70]\n",
    "start = time.time()\n",
    "#vertical_likelihood_tensor = np.load(f\"/home/jacob/xlc_sim_outputs/notebook_outputs/pixel-row_likelihood_tensor.npy\")\n",
    "def likelihoodfnc(par):\n",
    "    P=0\n",
    "    full_likelihood_tensor = np.load(f\"/home/jacob/xlc_sim_outputs/notebook_outputs/likelihood_tensor_0_360.npy\")\n",
    "    #iterate through each event, toss out any with pixel>32, as these are on the bottom of xlcal\n",
    "    for i in range(len(data_set['rotationangle'])):\n",
    "        if (data_set['horizontal_pixel'][i] < 32):# & (data_set['pixel_row'][i] < 31):\n",
    "            horizontal_pixel = data_set['horizontal_pixel'][i]\n",
    "\n",
    "            #Get the rotation angle for each event\n",
    "            rotation_angle = int(data_set['rotationangle'][i])\n",
    "            \n",
    "            angle = polang_model(data_set['energy'][i],par[0],par[1])\n",
    "            PD = polfrac_model(data_set['energy'][i],par[2],par[3])\n",
    "            #angle = par[0]\n",
    "            #PD = par[1]\n",
    "            \n",
    "            #Get the seperation between PA and the interager abover PA that is stored in the lookup table\n",
    "            x = np.ceil(angle) - angle\n",
    "            \n",
    "            # Get the likelihood of the polarization from array that are just above and below the expected polarization\n",
    "            if angle > 180:\n",
    "                angle -= 180\n",
    "            elif angle < 0:\n",
    "                angle += 180\n",
    "            #if (PD <= 1) & (PD > 0):\n",
    "            if True:\n",
    "                if PD > 1:\n",
    "                    PD = 1\n",
    "                z1 = full_likelihood_tensor[int(np.ceil(horizontal_pixel-1)),int(np.floor(angle)),int(np.ceil(PD*100)),rotation_angle]\n",
    "                z2 = full_likelihood_tensor[int(np.ceil(horizontal_pixel-1)),int(np.ceil(angle)),int(np.ceil(PD*100)),rotation_angle]\n",
    "    \n",
    "                z3 = full_likelihood_tensor[int(np.ceil(horizontal_pixel-1)),int(np.ceil(angle)),int(np.floor(PD*100)),rotation_angle]\n",
    "                z4 = full_likelihood_tensor[int(np.ceil(horizontal_pixel-1)),int(np.floor(angle)),int(np.floor(PD*100)),rotation_angle]\n",
    "\n",
    "                # Using the 4 nearest Polarization points, using the distance from them to the expected point as the weight, weight the likelihoods\n",
    "                dx1 = int(np.floor(angle)) - angle\n",
    "                dy1 = int(np.ceil(PD*100)) - (PD*100)\n",
    "                a = 1/np.hypot(dx1,dy1)\n",
    "                \n",
    "                dx2 = int(np.ceil(angle)) - angle\n",
    "                dy2 = int(np.ceil(PD*100)) - (PD*100)\n",
    "                b = 1/np.hypot(dx2,dy2)\n",
    "    \n",
    "                dx3 = int(np.ceil(angle)) - angle\n",
    "                dy3 = int(np.floor(PD*100)) - (PD*100)\n",
    "                c = 1/np.hypot(dx3,dy3)\n",
    "                \n",
    "                dx4 = int(np.floor(angle)) - angle\n",
    "                dy4 = int(np.floor(PD*100)) - (PD*100)\n",
    "                d = 1/np.hypot(dx4,dy4)\n",
    "                \n",
    "                # weigh likelihoods with 1/hypot\n",
    "                likelihood = ((a*z1)+(b*z2)+(c*z3)+(d*z4))/(a+b+c+d)\n",
    "                a = -np.log(np.abs(PD*100))\n",
    "                if a >= 0:\n",
    "                    likelihood += a\n",
    "                if PD < 0:\n",
    "                    likelihood += 1000\n",
    "            \n",
    "                \n",
    "            '''\n",
    "            #When I get Energy Resolved Simulations: this is future code\n",
    "            Energy = data_set['energy'][i]\n",
    "            if (Energy < 70) & (Energy > 20):\n",
    "                x1 = vertical_likelihood_tensor[0,int(np.ceil(data_set['pixel_row'][i])),int(np.ceil(Energy/10))]\n",
    "                x2 = vertical_likelihood_tensor[0,int(np.ceil(data_set['pixel_row'][i])),int(np.floor(Energy/10))]\n",
    "                \n",
    "                \n",
    "                dx1 = np.ceil(Energy/10) - Energy/10\n",
    "                dx2 = Energy/10 - np.floor(Energy/10)\n",
    "                energy_dep_vertical_pixel_likelihood = (dx1 * x1 + dx2 * x2)/(dx1+dx2)\n",
    "            elif Energy >= 70:\n",
    "                energy_dep_vertical_pixel_likelihood = x2 = vertical_likelihood_tensor[0,int(np.ceil(data_set['pixel_row'][i])),int(7)]\n",
    "            elif Energy <= 20:\n",
    "                energy_dep_vertical_pixel_likelihood = x2 = vertical_likelihood_tensor[0,int(np.ceil(data_set['pixel_row'][i])),int(2)]\n",
    "            \n",
    "            likelihood += energy_dep_vertical_pixel_likelihood\n",
    "            '''\n",
    "            P += likelihood\n",
    "    return P\n",
    "\n",
    "fitConst = False\n",
    "if fitConst:\n",
    "#res = opt.minimize(likelihoodfnc,np.array([45,0.1,0.45,0.1]),method='nelder-mead',bounds = ((0,180),(-5,5),(0,1),(-1,1)),options={\"fatol\":1E-3})\n",
    "#res = opt.basinhopping(likelihoodfnc,np.array([45,35/90,0.45,0.5/90]),minimizer_kwargs={'method':'nelder-mead','bounds':((0,180),(-180/90,180/90),(0,1),(-1/90,1/90))},niter=5)\n",
    "    res = opt.basinhopping(likelihoodfnc,np.array([45,0,0.45,0]),minimizer_kwargs={'method':'nelder-mead','bounds':((0,180),(-1e-7,1e-7),(0,1),(-1e-7,1e-7))},niter=5)\n",
    "\n",
    "if not fitConst:\n",
    "    res = opt.basinhopping(likelihoodfnc,np.array([50,20/90,0.3,0.2/90]),minimizer_kwargs={'method':'nelder-mead','bounds':((0,180),(-180/90,180/90),(0,1),(-1/90,1/90))},niter=3)\n",
    "\n",
    "print(res)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d86a538-c802-4f1d-bc4a-ec9baa0716a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50de4d1-0dad-49a7-8ece-2ffc9f47b468",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = np.arange(10,90,1)\n",
    "%matplotlib inline\n",
    "fig,ax = plt.subplots(2,1,sharex = True)\n",
    "ax[0].plot(E,polfrac_model(E,res.x[2],res.x[3]),label='Model')\n",
    "ax[0].plot(E,polfrac_model(E,0.3,0.2/90),label='Actual')\n",
    "ax[0].set_xlim(15,80)\n",
    "ax[0].set_ylabel(\"Pol Frac [0-1]\")\n",
    "ax[1].set_xlabel(\"Energy [keV]\")\n",
    "ax[1].plot(E,polang_model(E,res.x[0],res.x[1]))\n",
    "ax[1].plot(E,polang_model(E,50,20/90))\n",
    "ax[1].set_ylabel(\"Pol Angle [degrees]\")\n",
    "#ax[0].set_ylim(0,1)\n",
    "ax[0].legend()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cb7d9b-38a6-4c90-8322-c2e640de955e",
   "metadata": {},
   "source": [
    "## Test Code for adding Background"
   ]
  },
  {
   "cell_type": "raw",
   "id": "07af4686-4ea1-4f22-b408-dc69bb66b415",
   "metadata": {},
   "source": [
    "path_to_test_data = \"~/xlc_sim_outputs/flight_like/EnergyDepPDPA_nonconst_42.root.root\"\n",
    "data_set = r.RDataFrame('tree2',path_to_test_data).AsNumpy()\n",
    "import time\n",
    "PA_guess,PD_guess = 40,0.4\n",
    "opt_path = np.array([PA_guess,PD_guess])\n",
    "start = time.time()\n",
    "def get_source_bkg_rates():\n",
    "    return src , bkg , tot\n",
    "def likelihoodfnc(par):\n",
    "    P=0\n",
    "    full_likelihood_tensor = np.load(f\"/home/jacob/xlc_sim_outputs/notebook_outputs/likelihood_tensor_0_360.npy\")\n",
    "    #iterate through each event, toss out any with pixel>32, as these are on the bottom of xlcal\n",
    "    for i in range(len(data_set['rotationangle'])):\n",
    "        if (data_set['horizontal_pixel'][i] < 32):\n",
    "            horizontal_pixel = data_set['horizontal_pixel'][i]\n",
    "\n",
    "            #Get the rotation angle for each event\n",
    "            rotation_angle = int(data_set['rotationangle'][i])\n",
    "            \n",
    "            angle = polang_model(data_set['energy'][i],par[0],par[1])\n",
    "            PD = polfrac_model(data_set['energy'][i],par[2],par[3])\n",
    "            \n",
    "            #Get the seperation between PA and the interager abover PA that is stored in the lookup table\n",
    "            x = np.ceil(angle) - angle\n",
    "            \n",
    "            # Get the likelihood of the polarization 0.01/2 above and below the expected polarization, and \n",
    "            if angle > 180:\n",
    "                angle -= 180\n",
    "            elif angle < 0:\n",
    "                anlge += 180\n",
    "            if (PD <= 1) & (PD > 0):\n",
    "                z1 = full_likelihood_tensor[int(np.ceil(horizontal_pixel-1)),int(np.floor(angle)),int(np.ceil(PD*100)),rotation_angle]\n",
    "                z2 = full_likelihood_tensor[int(np.ceil(horizontal_pixel-1)),int(np.ceil(angle)),int(np.ceil(PD*100)),rotation_angle]\n",
    "    \n",
    "                z3 = full_likelihood_tensor[int(np.ceil(horizontal_pixel-1)),int(np.ceil(angle)),int(np.floor(PD*100)),rotation_angle]\n",
    "                z4 = full_likelihood_tensor[int(np.ceil(horizontal_pixel-1)),int(np.floor(angle)),int(np.floor(PD*100)),rotation_angle]\n",
    "    \n",
    "                dx1 = int(np.floor(angle)) - angle\n",
    "                dy1 = int(np.ceil(PD*100)) - (PD*100)\n",
    "                a = 1/np.hypot(dx1,dy1)\n",
    "                \n",
    "                dx2 = int(np.ceil(angle)) - angle\n",
    "                dy2 = int(np.ceil(PD*100)) - (PD*100)\n",
    "                b = 1/np.hypot(dx2,dy2)\n",
    "    \n",
    "                dx3 = int(np.ceil(angle)) - angle\n",
    "                dy3 = int(np.floor(PD*100)) - (PD*100)\n",
    "                c = 1/np.hypot(dx3,dy3)\n",
    "                \n",
    "                dx4 = int(np.floor(angle)) - angle\n",
    "                dy4 = int(np.floor(PD*100)) - (PD*100)\n",
    "                d = 1/np.hypot(dx4,dy4)\n",
    "    \n",
    "                likelihood = (a*z1+b*z2+c*z3+d*z4)/(a+b+c+d)\n",
    "            else:\n",
    "                likelihood = 10000000\n",
    "\n",
    "            # Define the 4 extremities around the point we are looking at\n",
    "            #y = par[1]\n",
    "            #weigh the \"up\" and \"down\" PD likelihoods to get the likelihood for a given PD\n",
    "            #likelihood = (y*pol_up) + ((1-y)*pol_down)\n",
    "            bkg_likelihood = full_likelihood_tensor[int(np.ceil(horizontal_pixel-1)),int(np.ceil(angle)),int(np.floor(0)),rotation_angle]\n",
    "            P -= np.log((src/(tot))*np.exp(-likelihood) + (bkg/(tot))*np.exp(-bkg_likelihood)) - np.log(Energy_Likelihood)\n",
    "    return P\n",
    "\n",
    "res = opt.minimize(likelihoodfnc,np.array([30,0.1,0.50,1]),method='nelder-mead',bounds = ((0,180),(-5,5),(0,1),(-1,1)),options={\"fatol\":1E-3})\n",
    "print(res)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f7d0cf-286b-4e25-bdc0-5eedb8fa9fa3",
   "metadata": {},
   "source": [
    "## Error Calculations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bd83d6-8e30-4d05-97cd-b167bd273e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_errors(par,index,error_step):\n",
    "    par = par.copy()\n",
    "    par2 = par.copy()\n",
    "    start = time.time()\n",
    "    value = res.fun\n",
    "    error = 0\n",
    "    par[index]\n",
    "    #get the error values by incrememnting PA/PD until we get a change in the log likelihood of 1.\n",
    "    while abs(res.fun - value) < 1:\n",
    "        if abs(res.fun - value) < 0.25:\n",
    "            error += error_step*5\n",
    "        else: \n",
    "            error += error_step\n",
    "        par2[index] = par[index]+error\n",
    "        value = likelihoodfnc(par2)\n",
    "    error -= 5*error_step\n",
    "    while abs(res.fun - value) < 1:\n",
    "        error += error_step/10\n",
    "        par2[index] = par[index]+error\n",
    "        value = likelihoodfnc(par2)\n",
    "    end = time.time()\n",
    "    print(end-start)\n",
    "    if error == 0:\n",
    "        print(\"smaller error on index {index}\")\n",
    "        error += get_errors(par,index,error_step/10)\n",
    "    return error\n",
    "\n",
    "par0e = get_errors(res.x,0,0.1)\n",
    "par2e = get_errors(res.x,2,0.0001)\n",
    "if not fitConst:\n",
    "    par1e = get_errors(res.x,1,0.0001)\n",
    "    par3e = get_errors(res.x,3,0.00001)\n",
    "else:\n",
    "    par1e = 0\n",
    "    par3e = 0\n",
    "\n",
    "upperbounds = [res.x[0]+par0e,res.x[1]+par1e,res.x[2]+par2e,res.x[3]+par3e]\n",
    "lowerbounds = [res.x[0]-par0e,res.x[1]-par1e,res.x[2]-par2e,res.x[3]-par3e]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a745d55-77de-43db-b63c-7a4d6400225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(upperbounds-res.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2eb4ac-8475-4969-a7bf-c407733991ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = np.arange(15,81,1)\n",
    "%matplotlib inline\n",
    "fig,ax = plt.subplots(2,1,sharex = True)\n",
    "ax[0].plot(E,polfrac_model(E,res.x[2],res.x[3]),label='Model')\n",
    "ax[0].plot(E,polfrac_model(E,0.3,0.2/90),label='Actual')\n",
    "ax[0].fill_between(E,polfrac_model(E,lowerbounds[2],lowerbounds[3]),polfrac_model(E,upperbounds[2],upperbounds[3]),label='error',color='#ffccff')\n",
    "ax[0].fill_between(E,polfrac_model(E,upperbounds[2],lowerbounds[3]),polfrac_model(E,lowerbounds[2],upperbounds[3]),color='#ffccff')\n",
    "\n",
    "ax[0].set_ylabel(\"Pol Frac [0-1]\")\n",
    "ax[1].set_xlabel(\"Energy [keV]\")\n",
    "ax[0].set_xlim(15,80)\n",
    "ax[1].plot(E,polang_model(E,res.x[0],res.x[1]))\n",
    "ax[1].plot(E,polang_model(E,50,20/90))\n",
    "ax[1].fill_between(E,polang_model(E,lowerbounds[0],lowerbounds[1]),polang_model(E,upperbounds[0],upperbounds[1]),label='error',color='#ffccff')\n",
    "ax[1].fill_between(E,polang_model(E,upperbounds[0],lowerbounds[1]),polfrac_model(E,lowerbounds[0],upperbounds[1]),color='#ffccff')\n",
    "ax[1].set_ylabel(\"Pol Angle [degrees]\")\n",
    "ax[0].legend()\n",
    "fig.tight_layout()\n",
    "fig.savefig('/home/jacob/Energy_dep_polarization_plots_realspec_withE.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74843aa8-261a-44f8-9ec2-530404405813",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "steps = 40\n",
    "width = 5\n",
    "if par1e == 0:\n",
    "    par1e = get_errors(res.x,1,0.0001)\n",
    "    par3e = get_errors(res.x,3,0.00001)\n",
    "pas_ = np.linspace(res.x[0] - (par0e*width),res.x[0] + (par0e*width),steps)\n",
    "pd_ = np.linspace(res.x[2] - (par2e*width),res.x[2] + (par2e*width),steps)\n",
    "#pd_ = np.linspace(0.50,0.75,steps)\n",
    "if pd_.max() > 1:\n",
    "    pd_ = np.linspace(res.x[2] - (par2e*width),0.75,steps)\n",
    "    pdmax = 0.75\n",
    "else:\n",
    "    pdmax = res.x[2] + (par2e*width)\n",
    "if pd_.min() < 0:\n",
    "    pd_ = np.linspace(0,pdmax,steps)\n",
    "paslopes_ = np.linspace(res.x[1] - (par1e*width),res.x[1] + (par1e*width), steps)\n",
    "pdslopes_ = np.linspace(res.x[3] - (par3e*width),res.x[3] + (par3e*width), steps)\n",
    "arrays = [pas_,paslopes_,pd_,pdslopes_]\n",
    "titles = ['PA_30 [degrees]','PA_slope [keV/degrees]' , 'PD_30 [0-1]', 'PD_slope [keV]' ]\n",
    "fig,ax = plt.subplots(4,4,figsize=(15, 15),layout=\"constrained\",sharex=False,sharey=False)\n",
    "for i in np.arange(4):\n",
    "    for j in np.arange(4):\n",
    "        #print(i,j)\n",
    "        par = list(res.x.copy())\n",
    "        if j < i:\n",
    "            \n",
    "            X,Y = np.meshgrid(arrays[i],arrays[j])\n",
    "            Z = np.empty_like(X)\n",
    "            for k in np.arange(len(arrays[i])):\n",
    "                for l in np.arange(len(arrays[j])):\n",
    "                    par[i] = arrays[i][k]\n",
    "                    par[j] = arrays[j][l]\n",
    "                    Z[k,l] = likelihoodfnc(par)\n",
    "            ax[i,j].contour(Y,X,Z.T,20,cmap='GnBu')\n",
    "            #ax[i,j].set_xlim(arrays[i].min(),arrays[i].max())\n",
    "            #ax[i,j].set_ylim(arrays[j].min(),arrays[j].max())\n",
    "            #ax[i,j].colorbar()\n",
    "            if i == 3:\n",
    "                ax[i,j].set_xlabel(titles[j])\n",
    "            if j == 0:\n",
    "                ax[i,j].set_ylabel(titles[i])\n",
    "            #if i != 0:\n",
    "            #    ax[i,j].tick_params(labelleft=None)\n",
    "            #if j != 0:\n",
    "            #    ax[i,j].tick_params(labelbottom=None)\n",
    "        elif i == j:\n",
    "            Z = []\n",
    "            for k in np.arange(len(arrays[i])):\n",
    "                par[i] = arrays[i][k]\n",
    "                Z = np.append(Z,likelihoodfnc(par))\n",
    "            ax[i,j].plot(arrays[i][:],Z)\n",
    "            #ax[i,j].tick_params(labelleft=None)\n",
    "            if i == 3 :\n",
    "                ax[i,j].set_xlabel(titles[j])\n",
    "        else:\n",
    "            ax[i,j].axis('off')\n",
    "            continue\n",
    "fig.savefig(\"/home/jacob/PolarizationLikelihoodErrors_realspec_smallPD.png\")\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ce1fc4-25e1-4efc-b50f-0dc86971fffc",
   "metadata": {},
   "source": [
    "## Stoke's Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826fd496-f085-4e6c-8726-10b5454cbe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = data_set['energy']\n",
    "constant_model = res.x.copy()\n",
    "sim_model = [50,20/90,0.3,0.2/90]\n",
    "\n",
    "def get_stokes(par,energy):\n",
    "    PA = polang_model(energy,par[0],par[1])\n",
    "    PD = polfrac_model(energy,par[2],par[3])\n",
    "\n",
    "    U = PD*np.sin(2*PA*np.pi/180)\n",
    "    Q = PD*np.cos(2*PA*np.pi/180)\n",
    "    U_I = U.sum()/len(energy)\n",
    "    Q_I = Q.sum()/len(energy)\n",
    "\n",
    "    return U_I,Q_I\n",
    "\n",
    "\n",
    "\n",
    "U,Q = get_stokes(sim_model,energy)\n",
    "U2,Q2 = get_stokes(constant_model,energy)\n",
    "table = [[U,Q,0.5*np.arctan2(U,Q)*180/np.pi,np.sqrt((U**2) + (Q**2))],[U2,Q2,0.5*np.arctan2(U2,Q2)*180/np.pi,np.sqrt((U2**2) + (Q2**2))]]\n",
    "table = pd.DataFrame(table,columns=['U','Q','recalculated PA','recalculated PD'],index=['Sim Model','Fit Model'])\n",
    "display(table)\n",
    "PD = np.sqrt((U**2) + (Q**2))\n",
    "PA = 0.5*np.arctan2(U,Q)*180/np.pi\n",
    "print(1/np.sqrt(2*len(energy)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d76070-0ee7-48d2-b007-0d36374531df",
   "metadata": {},
   "source": [
    "## Old But potentially useful code"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0f0d2175-3161-4fe6-80ca-297e0664128d",
   "metadata": {},
   "source": [
    "probs = np.zeros(40)\n",
    "\n",
    "\n",
    "def build_prob_array(File):\n",
    "    Prob_DataFrame = pd.DataFrame(index = np.arange(1,41,1))\n",
    "    for tree in range(len(File.GetListOfKeys())):\n",
    "        fTree = File.Get(f\"tree_{tree}\")\n",
    "        prob_hist = r.TH1D('prob_hist','prob_hist',len(xbin)-1,xbin)\n",
    "        for event in fTree:\n",
    "            if fTree.horizontal_pixel < 32:\n",
    "                prob_hist.Fill(fTree.horizontal_pixel)\n",
    "        prob_hist.Scale(1/prob_hist.Integral(),\"width\")\n",
    "        for i in range(40):\n",
    "            j = i+1\n",
    "            probs[i] = prob_hist.GetBinContent(j)\n",
    "        prob_hist.Delete()\n",
    "        df = pd.DataFrame(index = np.arange(1,41,1))\n",
    "        df[f'{tree}'] = probs\n",
    "        \n",
    "        Prob_DataFrame = pd.concat([Prob_DataFrame,df],axis=1).copy()\n",
    "    return Prob_DataFrame\n",
    "\n",
    "import re\n",
    "def get_numbers_from_filename(filename):\n",
    "    return re.search(r'\\d+', filename).group(0)\n",
    "    \n",
    "likelihoodfiles = sorted(glob(f'/mnt/d/VaryingRotationAngle/SimData_Histograms_RotAng*.root'))\n",
    "likelihood_list = []\n",
    "for i,f in enumerate(likelihoodfiles):\n",
    "\n",
    "    rot_ang = get_numbers_from_filename(f)\n",
    " \n",
    "    pol_prob_dataframe = build_prob_array(File1)\n",
    "    pol_prob_dataframe = pol_prob_dataframe.loc[pol_prob_dataframe.index < 32]\n",
    "    pol_prob_dataframe['pixel'] = np.arange(1,32,1)\n",
    "\n",
    "    pol_likelihoods = []\n",
    "    likelihoods_array_2D = np.empty_like(unpol_prob_dataframe.to_numpy())\n",
    "    unpol_likelihoods = np.zeros([181,31])\n",
    "    pol_prob_dataframe['180'] = pol_prob_dataframe['0']\n",
    "    for i in range(0,181):\n",
    "        unpol_likelihoods[i] = unpol_prob_dataframe['Probs'].to_numpy()\n",
    "    pol_likelihoods = unpol_likelihoods.T\n",
    "    for x in np.arange(0,1,0.001):\n",
    "        pol = pol_prob_dataframe.drop('pixel',axis=1).to_numpy()\n",
    "        unpol = unpol_prob_dataframe.copy()\n",
    "        likelihoods = ((1-x)*unpol_likelihoods.T) + ((x)*pol)\n",
    "        pol_likelihoods = np.dstack((pol_likelihoods,likelihoods))\n",
    "    likelihood_list.append(pol_likelihoods)\n",
    "full_likelihood_tensor = np.stack(likelihood_list, axis=3)\n",
    "\n",
    "print(full_likelihood_tensor.shape)\n",
    "\n",
    "np.save(\"/home/jacob/xlc_sim_outputs/notebook_outputs/likelihood_tensor.npy\",full_likelihood_tensor)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c4710344-eba1-45a4-a9c5-885281394cd2",
   "metadata": {},
   "source": [
    "#x = np.arange(0,1,0.05)\n",
    "#y = np.arange(0,180,5)\n",
    "#X, Y = np.meshgrid(x, y)\n",
    "\n",
    "a = np.arange(0,1,0.1)\n",
    "b = np.arange(0,180,60)\n",
    "n, m = np.meshgrid(a, b)\n",
    "R = np.sqrt(n**2 + m**2)\n",
    "c = np.sin(R)\n",
    "Z = likelihoodfnc([m,n])\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw=dict(projection='3d'))\n",
    "#rgb = ls.shade(Z, cmap=cm.gist_earth, vert_exag=0.1, blend_mode='soft')\n",
    "ax.plot_surface(n, m,Z )#, facecolors=rgb,linewidth=0, antialiased=False, shade=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f2e23efd-1ee6-4c01-a0b4-01fc3a73e269",
   "metadata": {},
   "source": [
    "fFile = TFile.Open(path_to_test_data)\n",
    "data_tree = fTree = fFile.Get(f\"tree2\")\n",
    "data_hist = r.TH1D('data_hist','data_hist',len(xbin)-1,xbin)\n",
    "for event in data_tree:\n",
    "    if data_tree.horizontal_pixel < 32:\n",
    "        data_hist.Fill(data_tree.horizontal_pixel)\n",
    "c = TCanvas(\"\",\"\",500,500)\n",
    "data_hist.Draw()\n",
    "c.Draw('Hist')\n",
    "\n",
    "ncount=0\n",
    "\n",
    "def likelihoodfunction(npa, gi,f,par,iflag):\n",
    "    global ncount\n",
    "    P = 0\n",
    "    PA = par[0]\n",
    "    x = np.ceil(PA) - PA\n",
    "    pol = (x*pol_prob_dataframe[str(int(np.ceil(PA)))]) + ((1-x)*pol_prob_dataframe[str(int(np.floor(PA)))])\n",
    "    unpol = unpol_prob_dataframe.copy()\n",
    "    likelihoods = ((1-par[1])*unpol['Probs']) + ((par[1])*pol)\n",
    "    likelihoods = pd.DataFrame(likelihoods,columns = ['probs'])\n",
    "    likelihoods['pixel'] = unpol['pixel']\n",
    "    for event in data_tree:\n",
    "        if data_tree.horizontal_pixel < 32:\n",
    "            p = likelihoods['probs'].loc[likelihoods['pixel'] == data_tree.horizontal_pixel].values\n",
    "            P += p\n",
    "    f.value = -P[0]\n",
    "    ncount += 1\n",
    "#print(likelihoodfunction(par = par))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "40171ad1-0a46-4322-9c26-ef9a7be83e69",
   "metadata": {},
   "source": [
    "import scipy.optimize as opt\n",
    "from optimparallel import minimize_parallel\n",
    "def likelihoodfnc(par):\n",
    "    print(par)\n",
    "    global ncount\n",
    "    P = 0\n",
    "    for event in data_tree:\n",
    "        if data_tree.horizontal_pixel < 32:\n",
    "            if data_tree.rotationangle > 180:\n",
    "                rotation_angle = np.round(data_tree.rotationangle,5) - 180\n",
    "            else:\n",
    "                rotation_angle = np.round(data_tree.rotationangle,5)\n",
    "            rotation_adjusted_PA = par[0] - (rotation_angle)\n",
    "            if rotation_adjusted_PA >= 180.0:\n",
    "                rotation_adjusted_PA -= 180.0\n",
    "            elif rotation_adjusted_PA < 0.0:\n",
    "                rotation_adjusted_PA += 180.0\n",
    "            if np.ceil(rotation_adjusted_PA) == 180:\n",
    "                ceil = 0\n",
    "            else:\n",
    "                ceil = np.ceil(rotation_adjusted_PA)\n",
    "            x = np.ceil(rotation_adjusted_PA) - rotation_adjusted_PA\n",
    "            pol = (x*pol_prob_dataframe[str(int(ceil))]) + ((1-x)*pol_prob_dataframe[str(int(np.floor(rotation_adjusted_PA)))])\n",
    "            unpol = unpol_prob_dataframe.copy()\n",
    "            likelihoods = ((1-par[1])*unpol['Probs']) + ((par[1])*pol)\n",
    "            likelihoods = pd.DataFrame(likelihoods,columns = ['probs'])\n",
    "            likelihoods['pixel'] = unpol['pixel']\n",
    "            p = np.log(likelihoods['probs'].loc[likelihoods['pixel'] == data_tree.horizontal_pixel].values)\n",
    "            P += p\n",
    "    return -P\n",
    "#res = opt.minimize(likelihoodfnc,np.array([40,0.40]),method='nelder-mead',bounds = ((0,180),(0,1)))\n",
    "#res = opt.minimize(likelihoodfnc,np.array([40,0.40]),method='COBYLA',bounds = ((0,180),(0,1)),options={\"maxiter\":5})\n",
    "#res = minimize_parallel(fun=likelihoodfnc, x0 = np.array([PA_initialguess,PD_initialguess]),bounds= ((0,180),(0,1)),parallel={'loginfo':True,'time':True})\n",
    "#res.time\n",
    "#print(res)\n",
    "\n",
    "print(likelihoodfnc([40,0.4]))\n",
    "#x1, x2 = res.loginfo['x'][:,0], res.loginfo['x'][:,1]\n",
    "#plt.plot(x1, x2, '-o')\n",
    "#plt.plot(x1[-1:], x2[-1:], '-o', color='red', markersize=50, marker='+')\n",
    "#plt.text(1.2, 1, 'start')\n",
    "#plt.xlabel('$PA$'); plt.ylabel('$PD$')\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb3daea6-0cce-498c-a875-c604faf17a61",
   "metadata": {},
   "source": [
    "pol_likelihoods = []\n",
    "likelihoods_array_2D = np.empty_like(unpol_prob_dataframe.to_numpy())\n",
    "unpol_likelihoods = np.zeros([181,31])\n",
    "pol_prob_dataframe['180'] = pol_prob_dataframe['0']\n",
    "for i in range(0,181):\n",
    "    unpol_likelihoods[i] = unpol_prob_dataframe['Probs'].to_numpy()\n",
    "pol_likelihoods = unpol_likelihoods.T\n",
    "for x in np.arange(0,1,0.001):\n",
    "    pol = pol_prob_dataframe.drop('pixel',axis=1).to_numpy()\n",
    "    unpol = unpol_prob_dataframe.copy()\n",
    "    likelihoods = ((1-x)*unpol_likelihoods.T) + ((x)*pol)\n",
    "    pol_likelihoods = np.dstack((pol_likelihoods,likelihoods))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "024041d1-2e8e-4826-8dac-f34d4d1e094f",
   "metadata": {},
   "source": [
    "from iminuit import Minuit\n",
    "\n",
    "def likelihoodfnc(PA,PD):\n",
    "    par = np.array([PA,PD])\n",
    "    P = 0\n",
    "    x = np.ceil(par[0]) - par[0]\n",
    "    pol = (x*pol_prob_dataframe[str(int(np.ceil(par[0])))]) + ((1-x)*pol_prob_dataframe[str(int(np.floor(par[0])))])\n",
    "    unpol = unpol_prob_dataframe.copy()\n",
    "    likelihoods = ((1-par[1])*unpol['Probs']) + ((par[1])*pol)\n",
    "    likelihoods = pd.DataFrame(likelihoods,columns = ['probs'])\n",
    "    likelihoods['pixel'] = unpol['pixel']\n",
    "    for event in data_tree:\n",
    "        if data_tree.horizontal_pixel < 32:\n",
    "            p = np.log(likelihoods['probs'].loc[likelihoods['pixel'] == data_tree.horizontal_pixel].values)\n",
    "            P += p\n",
    "    return -P\n",
    "\n",
    "m = Minuit(likelihoodfnc, PA=40, PD=0.45)\n",
    "m.errors= (1,0.01)\n",
    "m.limits['PA'] = 0, 180\n",
    "m.limits['PD'] = 0,1\n",
    "m.migrad()\n",
    "print(m.values , m.errors)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "24891653-7dcc-4552-88e5-76a365b59444",
   "metadata": {},
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "for PD in np.array([0,0.45,1]):\n",
    "    ax1.plot(pol_prob_dataframe.index.values,((1-PD)*unpol_prob_dataframe['Probs']) + ((PD)*pol_prob_dataframe['45']),label=f'PD = {PD}')\n",
    "probs = np.zeros(31)\n",
    "bins = np.zeros(31)\n",
    "for i in range(31):\n",
    "    j = i+1\n",
    "    probs[i] = data_hist.GetBinContent(j)\n",
    "    bins[i] = data_hist.GetBinCenter(j)\n",
    "probs = probs/probs.sum()\n",
    "\n",
    "ax2.plot(bins,probs, color = 'red',label='test data')\n",
    "fig.legend()\n",
    "ax1.set_xlabel('Pixel')\n",
    "ax1.set_ylabel('Probabilitities')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4c6d2b9c-a1ad-4b96-a3c3-a6f9e4221886",
   "metadata": {},
   "source": [
    "gMinuit = r.TMinuit(3)\n",
    "gMinuit.SetFCN(likelihoodfunction)\n",
    "import ctypes\n",
    "arglist = array('d', 10*[0.])\n",
    "ierflg = ctypes.c_int(1982)\n",
    "\n",
    "arglist[0] = 1\n",
    "gMinuit.mnexcm(\"SET ERR\", arglist, 1, ierflg )\n",
    "\n",
    "vstart = array('d', (75,0.4))\n",
    "step = array('d',(5,0.1))\n",
    "\n",
    "gMinuit.mnparm(0,\"a1\",vstart[0],step[0],0,180,ierflg)\n",
    "gMinuit.mnparm(1,\"a2\",vstart[1],step[1],0,1,ierflg)\n",
    "\n",
    "arglist[0] = 500\n",
    "arglist[1] = 1.\n",
    "gMinuit.mnexcm(\"MIGRAD\",arglist,2,ierflg)\n",
    "# Best likelihood, vertical range to search, value of error in likelihood\n",
    "amin, edm, errdef = map(ctypes.c_double,(-1400, 1000,0.20))\n",
    "nvpar, nparx, icstat = ctypes.c_int(1983), ctypes.c_int(1984), ctypes.c_int(1985)\n",
    "gMinuit.mnstat( amin, edm, errdef, nvpar, nparx, icstat )\n",
    "gMinuit.mnprin( 3,amin.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1f42c0-41a9-45d7-bba8-9b5ad4028672",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
